{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76cde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers, constraints\n",
    "\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af48c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset_clean.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7630b93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlowDuration</th>\n",
       "      <th>TotalFwdPackets</th>\n",
       "      <th>TotalBackwardPackets</th>\n",
       "      <th>TotalLengthofFwdPackets</th>\n",
       "      <th>TotalLengthofBwdPackets</th>\n",
       "      <th>FwdPacketLengthMax</th>\n",
       "      <th>FwdPacketLengthMin</th>\n",
       "      <th>FwdPacketLengthMean</th>\n",
       "      <th>FwdPacketLengthStd</th>\n",
       "      <th>BwdPacketLengthMax</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>ActiveMean</th>\n",
       "      <th>ActiveStd</th>\n",
       "      <th>ActiveMax</th>\n",
       "      <th>ActiveMin</th>\n",
       "      <th>IdleMean</th>\n",
       "      <th>IdleStd</th>\n",
       "      <th>IdleMax</th>\n",
       "      <th>IdleMin</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DestinationPort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54865.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55054.0</th>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55055.0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46236.0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54863.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FlowDuration  TotalFwdPackets  TotalBackwardPackets  \\\n",
       "DestinationPort                                                        \n",
       "54865.0                   3.0              2.0                   0.0   \n",
       "55054.0                 109.0              1.0                   1.0   \n",
       "55055.0                  52.0              1.0                   1.0   \n",
       "46236.0                  34.0              1.0                   1.0   \n",
       "54863.0                   3.0              2.0                   0.0   \n",
       "\n",
       "                 TotalLengthofFwdPackets  TotalLengthofBwdPackets  \\\n",
       "DestinationPort                                                     \n",
       "54865.0                             12.0                      0.0   \n",
       "55054.0                              6.0                      6.0   \n",
       "55055.0                              6.0                      6.0   \n",
       "46236.0                              6.0                      6.0   \n",
       "54863.0                             12.0                      0.0   \n",
       "\n",
       "                 FwdPacketLengthMax  FwdPacketLengthMin  FwdPacketLengthMean  \\\n",
       "DestinationPort                                                                \n",
       "54865.0                         6.0                 6.0                  6.0   \n",
       "55054.0                         6.0                 6.0                  6.0   \n",
       "55055.0                         6.0                 6.0                  6.0   \n",
       "46236.0                         6.0                 6.0                  6.0   \n",
       "54863.0                         6.0                 6.0                  6.0   \n",
       "\n",
       "                 FwdPacketLengthStd  BwdPacketLengthMax  ...  \\\n",
       "DestinationPort                                          ...   \n",
       "54865.0                         0.0                 0.0  ...   \n",
       "55054.0                         0.0                 6.0  ...   \n",
       "55055.0                         0.0                 6.0  ...   \n",
       "46236.0                         0.0                 6.0  ...   \n",
       "54863.0                         0.0                 0.0  ...   \n",
       "\n",
       "                 min_seg_size_forward  ActiveMean  ActiveStd  ActiveMax  \\\n",
       "DestinationPort                                                           \n",
       "54865.0                          20.0         0.0        0.0        0.0   \n",
       "55054.0                          20.0         0.0        0.0        0.0   \n",
       "55055.0                          20.0         0.0        0.0        0.0   \n",
       "46236.0                          20.0         0.0        0.0        0.0   \n",
       "54863.0                          20.0         0.0        0.0        0.0   \n",
       "\n",
       "                 ActiveMin  IdleMean  IdleStd  IdleMax  IdleMin   Label  \n",
       "DestinationPort                                                          \n",
       "54865.0                0.0       0.0      0.0      0.0      0.0  BENIGN  \n",
       "55054.0                0.0       0.0      0.0      0.0      0.0  BENIGN  \n",
       "55055.0                0.0       0.0      0.0      0.0      0.0  BENIGN  \n",
       "46236.0                0.0       0.0      0.0      0.0      0.0  BENIGN  \n",
       "54863.0                0.0       0.0      0.0      0.0      0.0  BENIGN  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [col.replace(' ', '') for col in df.columns]\n",
    "df.columns = col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc30b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove target data with low sample count\n",
    "#show stats\n",
    "df = df.replace(['Heartbleed', 'Web_Attack_Sql_Injection', 'Infiltration'], np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c6e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a second target label column grouping normal data and attack data\n",
    "df['Attack'] = np.where(df['Label'] == 'BENIGN', 0, 1)\n",
    "\n",
    "attack_data = {'BENIGN': 'benign', \n",
    "            'DoS_Hulk': 'dos',\n",
    "            'PortScan': 'probe', \n",
    "            'DDoS': 'ddos',\n",
    "            'DoS_GoldenEye': 'dos',\n",
    "            'FTPPatator': 'brute_force',\n",
    "            'SSHPatator': 'brute_force', \n",
    "            'DoS_slowloris': 'dos', \n",
    "            'DoS_Slowhttptest': 'dos',\n",
    "            'Bot': 'botnet',\n",
    "            'Web_Attack_Brute_Force': 'web_based_attack', \n",
    "            'Web_Attack_XSS': 'web_based_attack'}\n",
    "\n",
    "# Creation of a third target label column specifying grouped attacks\n",
    "df['Label_Category'] = df['Label'].map(lambda x: attack_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546d94c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                    2035505\n",
       "DoS_Hulk                   171509\n",
       "DDoS                       128005\n",
       "PortScan                    57305\n",
       "DoS_GoldenEye               10279\n",
       "FTPPatator                   5480\n",
       "DoS_slowloris                5289\n",
       "DoS_Slowhttptest             5176\n",
       "SSHPatator                   3071\n",
       "Bot                          1943\n",
       "Web_Attack_Brute_Force       1445\n",
       "Web_Attack_XSS                652\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d8d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign              2035505\n",
       "dos                  192253\n",
       "ddos                 128005\n",
       "probe                 57305\n",
       "brute_force            8551\n",
       "web_based_attack       2097\n",
       "botnet                 1943\n",
       "Name: Label_Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6414f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2035505\n",
       "1     390154\n",
       "Name: Attack, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf41a7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Binary representation of data')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_attacks = df['Attack'].value_counts()\n",
    "train_attacks.plot(kind='barh', color='red')\n",
    "plt.title('Binary representation of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e8f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = ['Label', 'Label_Category', 'Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83190a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(data_labels, axis=1)\n",
    "y = df[data_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dab8929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BwdPSHFlags',\n",
       " 'BwdURGFlags',\n",
       " 'FwdAvgBytes/Bulk',\n",
       " 'FwdAvgPackets/Bulk',\n",
       " 'FwdAvgBulkRate',\n",
       " 'BwdAvgBytes/Bulk',\n",
       " 'BwdAvgPackets/Bulk',\n",
       " 'BwdAvgBulkRate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = np.array(list(X))\n",
    "to_drop = []\n",
    "for x in column_names:\n",
    "    size = X.groupby([x]).size()\n",
    "    # check for columns that only take one value\n",
    "    if (len(size.unique()) == 1):\n",
    "        to_drop.append(x)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d54b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(to_drop, axis=1)\n",
    "dataset_hold = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdeff923",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9de1d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TotalFwdPackets', 'TotalBackwardPackets', 'TotalLengthofFwdPackets',\n",
      "       'TotalLengthofBwdPackets', 'FwdPacketLengthMax', 'FwdPacketLengthMean',\n",
      "       'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMean',\n",
      "       'BwdPacketLengthStd', 'FwdIATStd', 'FwdIATMax', 'FwdHeaderLength',\n",
      "       'BwdHeaderLength', 'MaxPacketLength', 'PacketLengthMean',\n",
      "       'PacketLengthStd', 'PacketLengthVariance', 'AveragePacketSize',\n",
      "       'AvgBwdSegmentSize', 'SubflowFwdPackets', 'SubflowFwdBytes',\n",
      "       'SubflowBwdPackets', 'SubflowBwdBytes', 'act_data_pkt_fwd', 'IdleMean'],\n",
      "      dtype='object') 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TotalFwdPackets', 'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',\n",
      "       'FwdPacketLengthMax', 'FwdPacketLengthMean', 'BwdPacketLengthMean',\n",
      "       'BwdPacketLengthStd', 'FlowIATStd', 'FlowIATMax', 'FwdIATStd',\n",
      "       'MaxPacketLength', 'PacketLengthMean', 'PacketLengthStd',\n",
      "       'PacketLengthVariance', 'AveragePacketSize', 'AvgFwdSegmentSize',\n",
      "       'AvgBwdSegmentSize', 'SubflowFwdPackets', 'SubflowFwdBytes',\n",
      "       'SubflowBwdBytes', 'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
      "       'IdleMean'],\n",
      "      dtype='object') 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TotalFwdPackets', 'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',\n",
      "       'FwdPacketLengthMax', 'BwdPacketLengthMax', 'BwdPacketLengthMean',\n",
      "       'BwdPacketLengthStd', 'FlowIATMax', 'FwdIATStd', 'FwdHeaderLength',\n",
      "       'MaxPacketLength', 'PacketLengthMean', 'PacketLengthStd',\n",
      "       'PacketLengthVariance', 'AveragePacketSize', 'AvgBwdSegmentSize',\n",
      "       'SubflowFwdPackets', 'SubflowFwdBytes', 'SubflowBwdBytes',\n",
      "       'min_seg_size_forward', 'IdleMax'],\n",
      "      dtype='object') 21\n"
     ]
    }
   ],
   "source": [
    "y_label = y.Label\n",
    "y_label_category = y.Label_Category\n",
    "y_attack = y.Attack\n",
    "x1,x2,x3=X,X,X\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    if i ==0:\n",
    "        y = y_label\n",
    "        X =x1\n",
    "    elif i==1:\n",
    "        y=y_label_category\n",
    "        X=x2\n",
    "    else:\n",
    "        y=y_attack\n",
    "        X=x3\n",
    "\n",
    "    LE = LabelEncoder()\n",
    "\n",
    "    LE.fit(y)\n",
    "    y = LE.transform(y)\n",
    "    \n",
    " \n",
    "\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 50 , verbose=2))\n",
    "    sel.fit(X, y)\n",
    "\n",
    "\n",
    "    sel.get_support()\n",
    "\n",
    "    selected_feat= X.columns[(sel.get_support())]\n",
    "    input_layers = len(selected_feat)\n",
    "    print(selected_feat, len(selected_feat))\n",
    "\n",
    "    X = sel.transform(X)\n",
    "    #X_val = sel.transform(X_val)\n",
    "\n",
    "    if i==0:\n",
    "        y_Label = y\n",
    "\n",
    "    elif i==1:\n",
    "        y_Label_Category = y\n",
    "    else:\n",
    "        y_Attack = y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3371cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential(X, ,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "524e72e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a14eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_Label_Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "510ac398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc5d24bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde17463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03ab5f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Random forrest classifier, training for loop 1 ... this loop contains 12 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Original labels accuracy =  0.99\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                Benign       0.99      1.00      0.99    407101\n",
      "              DoS_Hulk       1.00      0.02      0.04       388\n",
      "                  DDos       1.00      1.00      1.00     25601\n",
      "              PortScan       0.99      0.83      0.91      2056\n",
      "         DoS_GoldenEye       1.00      0.95      0.97     34302\n",
      "            FTPPatator       0.89      0.76      0.82      1035\n",
      "         DoS_slowlorus       0.98      0.57      0.72      1058\n",
      "      DoS_Slowhttptest       0.99      0.99      0.99      1096\n",
      "            SSHPatator       0.98      0.98      0.98     11461\n",
      "                   Bot       1.00      0.93      0.97       614\n",
      "Web_Attack_Brute_Force       0.00      0.00      0.00       289\n",
      "        Web_Attack_XSS       0.00      0.00      0.00       131\n",
      "\n",
      "              accuracy                           0.99    485132\n",
      "             macro avg       0.82      0.67      0.70    485132\n",
      "          weighted avg       0.99      0.99      0.99    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random forrest classifier, training for loop 1 ... this loop contains 7 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Category labels accuracy =  0.99\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Benign       0.99      1.00      0.99    407101\n",
      "             dos       1.00      0.03      0.05       388\n",
      "            ddos       1.00      0.65      0.79      1710\n",
      "           probe       1.00      1.00      1.00     25601\n",
      "     brute_force       0.99      0.93      0.96     38451\n",
      "web_based_attack       0.97      0.98      0.98     11461\n",
      "          botnet       0.00      0.00      0.00       420\n",
      "\n",
      "        accuracy                           0.99    485132\n",
      "       macro avg       0.85      0.65      0.68    485132\n",
      "    weighted avg       0.99      0.99      0.99    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random forrest classifier, training for loop 1 ... this loop contains 2 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Binary labels accuracy =  0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.99      1.00      0.99    407101\n",
      "      Attack       0.99      0.95      0.97     78031\n",
      "\n",
      "    accuracy                           0.99    485132\n",
      "   macro avg       0.99      0.97      0.98    485132\n",
      "weighted avg       0.99      0.99      0.99    485132\n",
      "\n",
      "Decision tree: f1=0.970 auc=0.995\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PR Score 0.994233529537161\n"
     ]
    }
   ],
   "source": [
    "def Randomforrest(X, y_Label, y_Label_Category, y_attack):\n",
    "    from sklearn.metrics import precision_score\n",
    "    import warnings\n",
    "    x1,x2,x3=X,X,X\n",
    "    \n",
    "    original_target_names=['Benign', 'DoS_Hulk', 'DDos', 'PortScan', 'DoS_GoldenEye', 'FTPPatator', 'DoS_slowlorus', 'DoS_Slowhttptest', 'SSHPatator', 'Bot', 'Web_Attack_Brute_Force', 'Web_Attack_XSS']\n",
    "    label_cat_names =['Benign', 'dos', 'ddos', 'probe','brute_force', 'web_based_attack', 'botnet']\n",
    "    label_attack_names = ['Benign', 'Attack']\n",
    "   \n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    loop_no =1\n",
    "    \n",
    "    for i in range(0,3):\n",
    "\n",
    "            if i ==0:\n",
    "                y = y_Label\n",
    "                X =x1\n",
    "\n",
    "            elif i==1:\n",
    "                y=y_Label_Category\n",
    "                X=x2\n",
    "\n",
    "            elif i==2:\n",
    "                y=y_attack\n",
    "                X=x3\n",
    "\n",
    "\n",
    "            X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)\n",
    "\n",
    "            X_test, X_val, y_test, y_val = train_test_split(X_hold, y_hold, test_size=0.5, random_state=0, stratify=y_hold)\n",
    "\n",
    "            min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "            # Apply normalisation to dataset\n",
    "            X_train = min_max_scaler.transform(X_train)\n",
    "            X_val = min_max_scaler.transform(X_val)\n",
    "            X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "            print(f'Random forrest classifier, training for loop {loop_no} ... this loop contains {len(np.unique(y))} target labels...')\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "            clf = RandomForestClassifier(n_estimators=32, max_depth=8, random_state=0, verbose=0, max_features='auto')\n",
    "\n",
    "            y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            if i == 0:\n",
    "                print(f'Original labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=original_target_names))\n",
    "            elif i == 1:\n",
    "                print(f'Category labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=label_cat_names))\n",
    "            elif i == 2:\n",
    "                print(f'Binary labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=label_attack_names))\n",
    "\n",
    "\n",
    "                clf_prob = clf.predict_proba(X_test)\n",
    "                clf_prob = clf_prob[:, 1] #keep probabilites for only positive outcomes\n",
    "\n",
    "                clf_precision, clf_recall, _ = precision_recall_curve(y_test, clf_prob)\n",
    "                pr_auc = average_precision_score(y_test, clf_prob, average='weighted')\n",
    "\n",
    "                clf_f1, clf_auc = f1_score(y_test, y_pred), auc(clf_recall, clf_precision)\n",
    "\n",
    "                print('Decision tree: f1=%.3f auc=%.3f' % (clf_f1, clf_auc))\n",
    "\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                plt.plot(clf_recall, clf_precision, label='auc={}'.format(pr_auc))\n",
    "                plt.title('Precision / Recall Curve')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.legend(loc='lower left')\n",
    "                plt.show()\n",
    "\n",
    "                print('Average PR Score {}'.format(pr_auc))\n",
    "            \n",
    "        \n",
    "Randomforrest(X, y_Label, y_Label_Category, y_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ddc5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Decision tree classifier, this itteration contains 12 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Original labels accuracy =  0.97\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                Benign       1.00      0.96      0.98    407101\n",
      "              DoS_Hulk       0.02      0.86      0.05       388\n",
      "                  DDos       1.00      1.00      1.00     25601\n",
      "              PortScan       0.98      0.98      0.98      2056\n",
      "         DoS_GoldenEye       0.99      0.99      0.99     34302\n",
      "            FTPPatator       0.94      0.98      0.96      1035\n",
      "         DoS_slowlorus       0.99      0.99      0.99      1058\n",
      "      DoS_Slowhttptest       0.91      1.00      0.95      1096\n",
      "            SSHPatator       0.91      1.00      0.95     11461\n",
      "                   Bot       0.96      0.96      0.96       614\n",
      "Web_Attack_Brute_Force       0.70      0.67      0.68       289\n",
      "        Web_Attack_XSS       0.37      0.35      0.36       131\n",
      "\n",
      "              accuracy                           0.97    485132\n",
      "             macro avg       0.81      0.89      0.82    485132\n",
      "          weighted avg       0.99      0.97      0.98    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Decision tree classifier, this itteration contains 7 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Category labels accuracy =  0.97\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Benign       1.00      0.96      0.98    407101\n",
      "             dos       0.02      0.85      0.05       388\n",
      "            ddos       0.96      0.98      0.97      1710\n",
      "           probe       1.00      1.00      1.00     25601\n",
      "     brute_force       0.99      0.99      0.99     38451\n",
      "web_based_attack       0.91      1.00      0.95     11461\n",
      "          botnet       0.94      0.87      0.90       420\n",
      "\n",
      "        accuracy                           0.97    485132\n",
      "       macro avg       0.83      0.95      0.83    485132\n",
      "    weighted avg       1.00      0.97      0.98    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Decision tree classifier, this itteration contains 2 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Binary labels accuracy =  1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      1.00      1.00    407101\n",
      "      Attack       0.98      0.99      0.99     78031\n",
      "\n",
      "    accuracy                           1.00    485132\n",
      "   macro avg       0.99      0.99      0.99    485132\n",
      "weighted avg       1.00      1.00      1.00    485132\n",
      "\n",
      "Decision tree: f1=0.987 auc=0.995\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PR Score 0.9929240393036676\n"
     ]
    }
   ],
   "source": [
    "def DecTree(X, y_Label, y_Label_Category, y_attack):\n",
    "    x1,x2,x3=X,X,X\n",
    "    original_target_names=['Benign', 'DoS_Hulk', 'DDos', 'PortScan', 'DoS_GoldenEye', 'FTPPatator', 'DoS_slowlorus', 'DoS_Slowhttptest', 'SSHPatator', 'Bot', 'Web_Attack_Brute_Force', 'Web_Attack_XSS']\n",
    "    label_cat_names =['Benign', 'dos', 'ddos', 'probe','brute_force', 'web_based_attack', 'botnet']\n",
    "    label_attack_names = ['Benign', 'Attack']\n",
    "\n",
    "    label_f1_results=[]\n",
    "    cat_f1_results=[]\n",
    "    bi_f1_results=[]\n",
    "\n",
    "    label_prec_results=[]\n",
    "    cat_prec_results=[]\n",
    "    bi_prec_results=[]\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "\n",
    "    for i in range(0,3):\n",
    "\n",
    "            if i ==0:\n",
    "                y = y_Label\n",
    "                X =x1\n",
    "\n",
    "            elif i==1:\n",
    "                y=y_Label_Category\n",
    "                X=x2\n",
    "\n",
    "            elif i==2:\n",
    "                y=y_attack\n",
    "                X=x3\n",
    "\n",
    "\n",
    "            X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)\n",
    "\n",
    "            X_test, X_val, y_test, y_val = train_test_split(X_hold, y_hold, test_size=0.5, random_state=0, stratify=y_hold)\n",
    "\n",
    "            min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "            # Apply normalisation to dataset\n",
    "            X_train = min_max_scaler.transform(X_train)\n",
    "            X_val = min_max_scaler.transform(X_val)\n",
    "            X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "            print(f'Decision tree classifier, this itteration contains {len(np.unique(y))} target labels...')\n",
    "            print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "            clf = DecisionTreeClassifier(random_state=0, class_weight=\"balanced\")\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if i == 0:\n",
    "                print(f'Original labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=original_target_names))\n",
    "            elif i == 1:\n",
    "                print(f'Category labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=label_cat_names))\n",
    "            elif i == 2:\n",
    "                print(f'Binary labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "                print(classification_report(y_test, y_pred, target_names=label_attack_names))\n",
    "\n",
    "\n",
    "                clf_prob = clf.predict_proba(X_test)\n",
    "                clf_prob = clf_prob[:, 1] #keep probabilites for only positive outcomes\n",
    "\n",
    "                clf_precision, clf_recall, _ = precision_recall_curve(y_test, clf_prob)\n",
    "                pr_auc = average_precision_score(y_test, clf_prob, average='weighted')\n",
    "\n",
    "                clf_f1, clf_auc = f1_score(y_test, y_pred), auc(clf_recall, clf_precision)\n",
    "\n",
    "                print('Decision tree: f1=%.3f auc=%.3f' % (clf_f1, clf_auc))\n",
    "\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                plt.plot(clf_recall, clf_precision, label='auc={}'.format(pr_auc))\n",
    "                plt.title('Precision / Recall Curve')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.legend(loc='lower left')\n",
    "                plt.show()\n",
    "\n",
    "                print('Average PR Score {}'.format(pr_auc))\n",
    "\n",
    "DecTree(X, y_Label, y_Label_Category, y_attack)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a5113b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Sequential NN, training loop 1 ... this loop contains 12 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Train on 1455395 samples, validate on 485132 samples\n",
      "Epoch 1/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.4519 - accuracy: 0.9058 - val_loss: 0.3367 - val_accuracy: 0.9225\n",
      "Epoch 2/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.3250 - accuracy: 0.9215 - val_loss: 0.2893 - val_accuracy: 0.9245\n",
      "Epoch 3/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2895 - accuracy: 0.9238 - val_loss: 0.2616 - val_accuracy: 0.9270\n",
      "Epoch 4/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2674 - accuracy: 0.9301 - val_loss: 0.2452 - val_accuracy: 0.9351\n",
      "Epoch 5/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2506 - accuracy: 0.9348 - val_loss: 0.2297 - val_accuracy: 0.9405\n",
      "Epoch 6/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2358 - accuracy: 0.9392 - val_loss: 0.2171 - val_accuracy: 0.9434\n",
      "Epoch 7/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2231 - accuracy: 0.9425 - val_loss: 0.2054 - val_accuracy: 0.9474\n",
      "Epoch 8/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2115 - accuracy: 0.9451 - val_loss: 0.1951 - val_accuracy: 0.9487\n",
      "Epoch 9/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2015 - accuracy: 0.9467 - val_loss: 0.1865 - val_accuracy: 0.9490\n",
      "Epoch 10/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1919 - accuracy: 0.9478 - val_loss: 0.1769 - val_accuracy: 0.9501\n",
      "Epoch 11/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1825 - accuracy: 0.9490 - val_loss: 0.1673 - val_accuracy: 0.9510\n",
      "Epoch 12/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1734 - accuracy: 0.9501 - val_loss: 0.1586 - val_accuracy: 0.9526\n",
      "Epoch 13/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1657 - accuracy: 0.9510 - val_loss: 0.1500 - val_accuracy: 0.9534\n",
      "Epoch 14/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1580 - accuracy: 0.9517 - val_loss: 0.1425 - val_accuracy: 0.9538\n",
      "Epoch 15/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1509 - accuracy: 0.9524 - val_loss: 0.1360 - val_accuracy: 0.9551\n",
      "Epoch 16/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1448 - accuracy: 0.9532 - val_loss: 0.1306 - val_accuracy: 0.9557\n",
      "Epoch 17/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1396 - accuracy: 0.9539 - val_loss: 0.1261 - val_accuracy: 0.9561\n",
      "Epoch 18/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1351 - accuracy: 0.9546 - val_loss: 0.1230 - val_accuracy: 0.9562\n",
      "Epoch 19/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.1176 - val_accuracy: 0.9569\n",
      "Epoch 20/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1275 - accuracy: 0.9611 - val_loss: 0.1151 - val_accuracy: 0.9691\n",
      "Epoch 21/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1248 - accuracy: 0.9642 - val_loss: 0.1121 - val_accuracy: 0.9697\n",
      "Epoch 22/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1222 - accuracy: 0.9656 - val_loss: 0.1102 - val_accuracy: 0.9700\n",
      "Epoch 23/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1202 - accuracy: 0.9661 - val_loss: 0.1090 - val_accuracy: 0.9699\n",
      "Epoch 24/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1183 - accuracy: 0.9662 - val_loss: 0.1062 - val_accuracy: 0.9688\n",
      "Epoch 25/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1171 - accuracy: 0.9661 - val_loss: 0.1048 - val_accuracy: 0.9681\n",
      "Epoch 26/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1158 - accuracy: 0.9661 - val_loss: 0.1045 - val_accuracy: 0.9673\n",
      "Epoch 27/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1146 - accuracy: 0.9662 - val_loss: 0.1040 - val_accuracy: 0.9680\n",
      "Epoch 28/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1137 - accuracy: 0.9660 - val_loss: 0.1043 - val_accuracy: 0.9665\n",
      "Epoch 29/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1127 - accuracy: 0.9664 - val_loss: 0.1030 - val_accuracy: 0.9664\n",
      "Epoch 30/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1118 - accuracy: 0.9663 - val_loss: 0.1015 - val_accuracy: 0.9687\n",
      "Epoch 31/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1112 - accuracy: 0.9664 - val_loss: 0.1017 - val_accuracy: 0.9681\n",
      "Epoch 32/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1106 - accuracy: 0.9665 - val_loss: 0.1001 - val_accuracy: 0.9678\n",
      "Epoch 33/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1097 - accuracy: 0.9665 - val_loss: 0.0999 - val_accuracy: 0.9681\n",
      "Epoch 34/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1091 - accuracy: 0.9666 - val_loss: 0.0986 - val_accuracy: 0.9682\n",
      "Epoch 35/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1089 - accuracy: 0.9667 - val_loss: 0.0985 - val_accuracy: 0.9680\n",
      "Epoch 36/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1079 - accuracy: 0.9669 - val_loss: 0.0977 - val_accuracy: 0.9682\n",
      "Epoch 37/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1073 - accuracy: 0.9670 - val_loss: 0.0985 - val_accuracy: 0.9701\n",
      "Epoch 38/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1071 - accuracy: 0.9672 - val_loss: 0.0971 - val_accuracy: 0.9685\n",
      "Epoch 39/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1065 - accuracy: 0.9673 - val_loss: 0.0969 - val_accuracy: 0.9693\n",
      "Epoch 40/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1060 - accuracy: 0.9674 - val_loss: 0.0967 - val_accuracy: 0.9674\n",
      "Epoch 41/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1054 - accuracy: 0.9675 - val_loss: 0.0958 - val_accuracy: 0.9692\n",
      "Epoch 42/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1052 - accuracy: 0.9676 - val_loss: 0.0955 - val_accuracy: 0.9694\n",
      "Epoch 43/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1048 - accuracy: 0.9676 - val_loss: 0.0949 - val_accuracy: 0.9696\n",
      "Epoch 44/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1044 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9696\n",
      "Epoch 45/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1039 - accuracy: 0.9680 - val_loss: 0.0939 - val_accuracy: 0.9693\n",
      "Epoch 46/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1033 - accuracy: 0.9681 - val_loss: 0.0942 - val_accuracy: 0.9682\n",
      "Epoch 47/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.1027 - accuracy: 0.9685 - val_loss: 0.0924 - val_accuracy: 0.9694\n",
      "Epoch 48/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1028 - accuracy: 0.9686 - val_loss: 0.0934 - val_accuracy: 0.9706\n",
      "Epoch 49/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1020 - accuracy: 0.9685 - val_loss: 0.0917 - val_accuracy: 0.9698\n",
      "Epoch 50/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1015 - accuracy: 0.9688 - val_loss: 0.0916 - val_accuracy: 0.9807\n",
      "Epoch 51/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1010 - accuracy: 0.9690 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
      "Epoch 52/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1003 - accuracy: 0.9691 - val_loss: 0.0921 - val_accuracy: 0.9704\n",
      "Epoch 53/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1000 - accuracy: 0.9693 - val_loss: 0.0903 - val_accuracy: 0.9704\n",
      "Epoch 54/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0996 - accuracy: 0.9694 - val_loss: 0.0897 - val_accuracy: 0.9700\n",
      "Epoch 55/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0988 - accuracy: 0.9697 - val_loss: 0.0893 - val_accuracy: 0.9695\n",
      "Epoch 56/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0987 - accuracy: 0.9696 - val_loss: 0.0893 - val_accuracy: 0.9705\n",
      "Epoch 57/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0980 - accuracy: 0.9699 - val_loss: 0.0878 - val_accuracy: 0.9709\n",
      "Epoch 58/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.0890 - val_accuracy: 0.9702\n",
      "Epoch 59/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0971 - accuracy: 0.9702 - val_loss: 0.0877 - val_accuracy: 0.9711\n",
      "Epoch 60/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0873 - val_accuracy: 0.9707\n",
      "Epoch 61/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0964 - accuracy: 0.9706 - val_loss: 0.0873 - val_accuracy: 0.9705\n",
      "Epoch 62/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0961 - accuracy: 0.9706 - val_loss: 0.0868 - val_accuracy: 0.9823\n",
      "Epoch 63/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0957 - accuracy: 0.9706 - val_loss: 0.0869 - val_accuracy: 0.9714\n",
      "Epoch 64/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0952 - accuracy: 0.9707 - val_loss: 0.0867 - val_accuracy: 0.9717\n",
      "Epoch 65/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0951 - accuracy: 0.9709 - val_loss: 0.0854 - val_accuracy: 0.9714\n",
      "Epoch 66/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0944 - accuracy: 0.9711 - val_loss: 0.0860 - val_accuracy: 0.9714\n",
      "Epoch 67/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0943 - accuracy: 0.9711 - val_loss: 0.0850 - val_accuracy: 0.9721\n",
      "Epoch 68/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0937 - accuracy: 0.9713 - val_loss: 0.0843 - val_accuracy: 0.9704\n",
      "Epoch 69/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0938 - accuracy: 0.9715 - val_loss: 0.0839 - val_accuracy: 0.9830\n",
      "Epoch 70/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0931 - accuracy: 0.9716 - val_loss: 0.0848 - val_accuracy: 0.9736\n",
      "Epoch 71/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0926 - accuracy: 0.9716 - val_loss: 0.0835 - val_accuracy: 0.9828\n",
      "Epoch 72/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0926 - accuracy: 0.9716 - val_loss: 0.0831 - val_accuracy: 0.9827\n",
      "Epoch 73/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0924 - accuracy: 0.9715 - val_loss: 0.0821 - val_accuracy: 0.9834\n",
      "Epoch 74/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0920 - accuracy: 0.9717 - val_loss: 0.0823 - val_accuracy: 0.9726\n",
      "Epoch 75/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0917 - accuracy: 0.9719 - val_loss: 0.0822 - val_accuracy: 0.9831\n",
      "Epoch 76/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0911 - accuracy: 0.9723 - val_loss: 0.0811 - val_accuracy: 0.9725\n",
      "Epoch 77/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0910 - accuracy: 0.9721 - val_loss: 0.0811 - val_accuracy: 0.9726\n",
      "Epoch 78/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0907 - accuracy: 0.9721 - val_loss: 0.0812 - val_accuracy: 0.9712\n",
      "Epoch 79/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0905 - accuracy: 0.9722 - val_loss: 0.0808 - val_accuracy: 0.9727\n",
      "Epoch 80/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0901 - accuracy: 0.9724 - val_loss: 0.0808 - val_accuracy: 0.9726\n",
      "Original labels accuracy =  0.97\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                Benign       0.97      1.00      0.98    407101\n",
      "              DoS_Hulk       0.00      0.00      0.00       388\n",
      "                  DDos       0.99      0.98      0.99     25601\n",
      "              PortScan       0.95      0.85      0.90      2056\n",
      "         DoS_GoldenEye       1.00      0.91      0.95     34302\n",
      "            FTPPatator       0.86      0.83      0.84      1035\n",
      "         DoS_slowlorus       0.91      0.54      0.68      1058\n",
      "      DoS_Slowhttptest       0.97      0.72      0.83      1096\n",
      "            SSHPatator       0.83      0.49      0.61     11461\n",
      "                   Bot       1.00      0.95      0.97       614\n",
      "Web_Attack_Brute_Force       0.00      0.00      0.00       289\n",
      "        Web_Attack_XSS       0.00      0.00      0.00       131\n",
      "\n",
      "              accuracy                           0.97    485132\n",
      "             macro avg       0.71      0.61      0.65    485132\n",
      "          weighted avg       0.97      0.97      0.97    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Sequential NN, training loop 2 ... this loop contains 7 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Train on 1455395 samples, validate on 485132 samples\n",
      "Epoch 1/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.4029 - accuracy: 0.9056 - val_loss: 0.2951 - val_accuracy: 0.9231\n",
      "Epoch 2/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2888 - accuracy: 0.9237 - val_loss: 0.2613 - val_accuracy: 0.9261\n",
      "Epoch 3/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2651 - accuracy: 0.9280 - val_loss: 0.2432 - val_accuracy: 0.9308\n",
      "Epoch 4/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2465 - accuracy: 0.9342 - val_loss: 0.2286 - val_accuracy: 0.9388\n",
      "Epoch 5/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2315 - accuracy: 0.9388 - val_loss: 0.2154 - val_accuracy: 0.9432\n",
      "Epoch 6/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2191 - accuracy: 0.9428 - val_loss: 0.2056 - val_accuracy: 0.9463\n",
      "Epoch 7/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2090 - accuracy: 0.9458 - val_loss: 0.1953 - val_accuracy: 0.9487\n",
      "Epoch 8/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.2006 - accuracy: 0.9478 - val_loss: 0.1878 - val_accuracy: 0.9496\n",
      "Epoch 9/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1932 - accuracy: 0.9489 - val_loss: 0.1809 - val_accuracy: 0.9508\n",
      "Epoch 10/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1861 - accuracy: 0.9499 - val_loss: 0.1737 - val_accuracy: 0.9510\n",
      "Epoch 11/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1788 - accuracy: 0.9508 - val_loss: 0.1666 - val_accuracy: 0.9520\n",
      "Epoch 12/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1715 - accuracy: 0.9513 - val_loss: 0.1594 - val_accuracy: 0.9523\n",
      "Epoch 13/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1638 - accuracy: 0.9518 - val_loss: 0.1521 - val_accuracy: 0.9527\n",
      "Epoch 14/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1569 - accuracy: 0.9521 - val_loss: 0.1454 - val_accuracy: 0.9528\n",
      "Epoch 15/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1500 - accuracy: 0.9524 - val_loss: 0.1386 - val_accuracy: 0.9536\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1442 - accuracy: 0.9528 - val_loss: 0.1330 - val_accuracy: 0.9549\n",
      "Epoch 17/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1393 - accuracy: 0.9532 - val_loss: 0.1278 - val_accuracy: 0.9537\n",
      "Epoch 18/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1346 - accuracy: 0.9537 - val_loss: 0.1238 - val_accuracy: 0.9556\n",
      "Epoch 19/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1308 - accuracy: 0.9544 - val_loss: 0.1198 - val_accuracy: 0.9561\n",
      "Epoch 20/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1274 - accuracy: 0.9563 - val_loss: 0.1165 - val_accuracy: 0.9570\n",
      "Epoch 21/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1243 - accuracy: 0.9588 - val_loss: 0.1153 - val_accuracy: 0.9665\n",
      "Epoch 22/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1220 - accuracy: 0.9612 - val_loss: 0.1120 - val_accuracy: 0.9675\n",
      "Epoch 23/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1196 - accuracy: 0.9631 - val_loss: 0.1106 - val_accuracy: 0.9689\n",
      "Epoch 24/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1179 - accuracy: 0.9642 - val_loss: 0.1076 - val_accuracy: 0.9693\n",
      "Epoch 25/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1161 - accuracy: 0.9650 - val_loss: 0.1063 - val_accuracy: 0.9695\n",
      "Epoch 26/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1149 - accuracy: 0.9654 - val_loss: 0.1060 - val_accuracy: 0.9700\n",
      "Epoch 27/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1134 - accuracy: 0.9658 - val_loss: 0.1042 - val_accuracy: 0.9692\n",
      "Epoch 28/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1124 - accuracy: 0.9658 - val_loss: 0.1039 - val_accuracy: 0.9702\n",
      "Epoch 29/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1113 - accuracy: 0.9660 - val_loss: 0.1030 - val_accuracy: 0.9689\n",
      "Epoch 30/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1102 - accuracy: 0.9661 - val_loss: 0.1013 - val_accuracy: 0.9684\n",
      "Epoch 31/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1089 - accuracy: 0.9663 - val_loss: 0.1005 - val_accuracy: 0.9666\n",
      "Epoch 32/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.1007 - val_accuracy: 0.9702\n",
      "Epoch 33/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1070 - accuracy: 0.9669 - val_loss: 0.0989 - val_accuracy: 0.9681\n",
      "Epoch 34/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1059 - accuracy: 0.9671 - val_loss: 0.0977 - val_accuracy: 0.9669\n",
      "Epoch 35/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1050 - accuracy: 0.9674 - val_loss: 0.0960 - val_accuracy: 0.9691\n",
      "Epoch 36/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1039 - accuracy: 0.9678 - val_loss: 0.0961 - val_accuracy: 0.9706\n",
      "Epoch 37/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1033 - accuracy: 0.9679 - val_loss: 0.0951 - val_accuracy: 0.9715\n",
      "Epoch 38/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1025 - accuracy: 0.9683 - val_loss: 0.0937 - val_accuracy: 0.9703\n",
      "Epoch 39/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1018 - accuracy: 0.9684 - val_loss: 0.0934 - val_accuracy: 0.9706\n",
      "Epoch 40/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1010 - accuracy: 0.9687 - val_loss: 0.0928 - val_accuracy: 0.9704\n",
      "Epoch 41/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1004 - accuracy: 0.9687 - val_loss: 0.0917 - val_accuracy: 0.9705\n",
      "Epoch 42/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0998 - accuracy: 0.9690 - val_loss: 0.0934 - val_accuracy: 0.9686\n",
      "Epoch 43/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0990 - accuracy: 0.9690 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 44/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0988 - accuracy: 0.9691 - val_loss: 0.0918 - val_accuracy: 0.9712\n",
      "Epoch 45/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0983 - accuracy: 0.9693 - val_loss: 0.0915 - val_accuracy: 0.9724\n",
      "Epoch 46/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0979 - accuracy: 0.9694 - val_loss: 0.0902 - val_accuracy: 0.9698\n",
      "Epoch 47/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0975 - accuracy: 0.9695 - val_loss: 0.0888 - val_accuracy: 0.9712\n",
      "Epoch 48/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0970 - accuracy: 0.9696 - val_loss: 0.0890 - val_accuracy: 0.9823\n",
      "Epoch 49/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0966 - accuracy: 0.9697 - val_loss: 0.0885 - val_accuracy: 0.9699\n",
      "Epoch 50/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0965 - accuracy: 0.9697 - val_loss: 0.0884 - val_accuracy: 0.9716\n",
      "Epoch 51/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.0959 - accuracy: 0.9700 - val_loss: 0.0874 - val_accuracy: 0.9708\n",
      "Epoch 52/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0957 - accuracy: 0.9700 - val_loss: 0.0879 - val_accuracy: 0.9715\n",
      "Epoch 53/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0955 - accuracy: 0.9700 - val_loss: 0.0867 - val_accuracy: 0.9714\n",
      "Epoch 54/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0950 - accuracy: 0.9703 - val_loss: 0.0866 - val_accuracy: 0.9714\n",
      "Epoch 55/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.0947 - accuracy: 0.9703 - val_loss: 0.0861 - val_accuracy: 0.9713\n",
      "Epoch 56/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.0946 - accuracy: 0.9704 - val_loss: 0.0876 - val_accuracy: 0.9716\n",
      "Epoch 57/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0941 - accuracy: 0.9705 - val_loss: 0.0854 - val_accuracy: 0.9824\n",
      "Epoch 58/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0940 - accuracy: 0.9704 - val_loss: 0.0860 - val_accuracy: 0.9717\n",
      "Epoch 59/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0939 - accuracy: 0.9706 - val_loss: 0.0861 - val_accuracy: 0.9715\n",
      "Epoch 60/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0935 - accuracy: 0.9707 - val_loss: 0.0861 - val_accuracy: 0.9702\n",
      "Epoch 61/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0931 - accuracy: 0.9707 - val_loss: 0.0840 - val_accuracy: 0.9717\n",
      "Epoch 62/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0931 - accuracy: 0.9708 - val_loss: 0.0845 - val_accuracy: 0.9825\n",
      "Epoch 63/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0930 - accuracy: 0.9709 - val_loss: 0.0859 - val_accuracy: 0.9733\n",
      "Epoch 64/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0926 - accuracy: 0.9710 - val_loss: 0.0852 - val_accuracy: 0.9720\n",
      "Epoch 65/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0924 - accuracy: 0.9711 - val_loss: 0.0841 - val_accuracy: 0.9719\n",
      "Epoch 66/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0922 - accuracy: 0.9711 - val_loss: 0.0832 - val_accuracy: 0.9720\n",
      "Epoch 67/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9720\n",
      "Epoch 68/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0917 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9720\n",
      "Epoch 69/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0916 - accuracy: 0.9713 - val_loss: 0.0843 - val_accuracy: 0.9828\n",
      "Epoch 70/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0916 - accuracy: 0.9714 - val_loss: 0.0832 - val_accuracy: 0.9828\n",
      "Epoch 71/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0913 - accuracy: 0.9715 - val_loss: 0.0829 - val_accuracy: 0.9705\n",
      "Epoch 72/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0909 - accuracy: 0.9716 - val_loss: 0.0818 - val_accuracy: 0.9719\n",
      "Epoch 73/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0907 - accuracy: 0.9718 - val_loss: 0.0828 - val_accuracy: 0.9829\n",
      "Epoch 74/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.0835 - val_accuracy: 0.9705\n",
      "Epoch 75/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0903 - accuracy: 0.9718 - val_loss: 0.0820 - val_accuracy: 0.9721\n",
      "Epoch 76/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0904 - accuracy: 0.9717 - val_loss: 0.0820 - val_accuracy: 0.9722\n",
      "Epoch 77/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0902 - accuracy: 0.9719 - val_loss: 0.0820 - val_accuracy: 0.9705\n",
      "Epoch 78/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.0899 - accuracy: 0.9720 - val_loss: 0.0821 - val_accuracy: 0.9726\n",
      "Epoch 79/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.0896 - accuracy: 0.9721 - val_loss: 0.0810 - val_accuracy: 0.9725\n",
      "Epoch 80/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.0891 - accuracy: 0.9723 - val_loss: 0.0807 - val_accuracy: 0.9722\n",
      "Category labels accuracy =  0.97\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Benign       0.97      1.00      0.98    407101\n",
      "             dos       1.00      0.01      0.03       388\n",
      "            ddos       0.99      0.81      0.89      1710\n",
      "           probe       0.99      0.98      0.99     25601\n",
      "     brute_force       0.99      0.88      0.93     38451\n",
      "web_based_attack       0.82      0.49      0.61     11461\n",
      "          botnet       0.00      0.00      0.00       420\n",
      "\n",
      "        accuracy                           0.97    485132\n",
      "       macro avg       0.82      0.60      0.63    485132\n",
      "    weighted avg       0.97      0.97      0.97    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Sequential NN, training loop 3 ... this loop contains 2 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Train on 1455395 samples, validate on 485132 samples\n",
      "Epoch 1/80\n",
      "1455395/1455395 [==============================] - 4s 3us/sample - loss: 0.2498 - accuracy: 0.9271 - val_loss: 0.2011 - val_accuracy: 0.9378\n",
      "Epoch 2/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1936 - accuracy: 0.9364 - val_loss: 0.1746 - val_accuracy: 0.9385\n",
      "Epoch 3/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1773 - accuracy: 0.9378 - val_loss: 0.1665 - val_accuracy: 0.9385\n",
      "Epoch 4/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1705 - accuracy: 0.9393 - val_loss: 0.1625 - val_accuracy: 0.9401\n",
      "Epoch 5/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1667 - accuracy: 0.9408 - val_loss: 0.1594 - val_accuracy: 0.9403\n",
      "Epoch 6/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1643 - accuracy: 0.9418 - val_loss: 0.1578 - val_accuracy: 0.9403\n",
      "Epoch 7/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1626 - accuracy: 0.9422 - val_loss: 0.1566 - val_accuracy: 0.9402\n",
      "Epoch 8/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1614 - accuracy: 0.9424 - val_loss: 0.1551 - val_accuracy: 0.9412\n",
      "Epoch 9/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1607 - accuracy: 0.9426 - val_loss: 0.1552 - val_accuracy: 0.9402\n",
      "Epoch 10/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1600 - accuracy: 0.9427 - val_loss: 0.1538 - val_accuracy: 0.9423\n",
      "Epoch 11/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1591 - accuracy: 0.9431 - val_loss: 0.1529 - val_accuracy: 0.9410\n",
      "Epoch 12/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1580 - accuracy: 0.9434 - val_loss: 0.1522 - val_accuracy: 0.9446\n",
      "Epoch 13/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1572 - accuracy: 0.9436 - val_loss: 0.1510 - val_accuracy: 0.9435\n",
      "Epoch 14/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1564 - accuracy: 0.9438 - val_loss: 0.1495 - val_accuracy: 0.9461\n",
      "Epoch 15/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1555 - accuracy: 0.9442 - val_loss: 0.1494 - val_accuracy: 0.9453\n",
      "Epoch 16/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1552 - accuracy: 0.9443 - val_loss: 0.1486 - val_accuracy: 0.9461\n",
      "Epoch 17/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1547 - accuracy: 0.9447 - val_loss: 0.1485 - val_accuracy: 0.9457\n",
      "Epoch 18/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1540 - accuracy: 0.9451 - val_loss: 0.1472 - val_accuracy: 0.9473\n",
      "Epoch 19/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1531 - accuracy: 0.9453 - val_loss: 0.1465 - val_accuracy: 0.9482\n",
      "Epoch 20/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1526 - accuracy: 0.9459 - val_loss: 0.1460 - val_accuracy: 0.9485\n",
      "Epoch 21/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1516 - accuracy: 0.9461 - val_loss: 0.1460 - val_accuracy: 0.9478\n",
      "Epoch 22/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1513 - accuracy: 0.9463 - val_loss: 0.1448 - val_accuracy: 0.9486\n",
      "Epoch 23/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1507 - accuracy: 0.9467 - val_loss: 0.1437 - val_accuracy: 0.9493\n",
      "Epoch 24/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1498 - accuracy: 0.9467 - val_loss: 0.1432 - val_accuracy: 0.9491\n",
      "Epoch 25/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1487 - accuracy: 0.9472 - val_loss: 0.1417 - val_accuracy: 0.9497\n",
      "Epoch 26/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1478 - accuracy: 0.9473 - val_loss: 0.1406 - val_accuracy: 0.9503\n",
      "Epoch 27/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1471 - accuracy: 0.9475 - val_loss: 0.1396 - val_accuracy: 0.9502\n",
      "Epoch 28/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1460 - accuracy: 0.9477 - val_loss: 0.1388 - val_accuracy: 0.9498\n",
      "Epoch 29/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1444 - accuracy: 0.9478 - val_loss: 0.1372 - val_accuracy: 0.9498\n",
      "Epoch 30/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1421 - accuracy: 0.9482 - val_loss: 0.1340 - val_accuracy: 0.9504\n",
      "Epoch 31/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1401 - accuracy: 0.9483 - val_loss: 0.1327 - val_accuracy: 0.9499\n",
      "Epoch 32/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1380 - accuracy: 0.9485 - val_loss: 0.1293 - val_accuracy: 0.9506\n",
      "Epoch 33/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1361 - accuracy: 0.9487 - val_loss: 0.1272 - val_accuracy: 0.9506\n",
      "Epoch 34/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.1334 - accuracy: 0.9490 - val_loss: 0.1240 - val_accuracy: 0.9506\n",
      "Epoch 35/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1319 - accuracy: 0.9492 - val_loss: 0.1221 - val_accuracy: 0.9504\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1306 - accuracy: 0.9491 - val_loss: 0.1206 - val_accuracy: 0.9506\n",
      "Epoch 37/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1294 - accuracy: 0.9493 - val_loss: 0.1200 - val_accuracy: 0.9507\n",
      "Epoch 38/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1286 - accuracy: 0.9499 - val_loss: 0.1176 - val_accuracy: 0.9501\n",
      "Epoch 39/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1276 - accuracy: 0.9503 - val_loss: 0.1174 - val_accuracy: 0.9526\n",
      "Epoch 40/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1274 - accuracy: 0.9507 - val_loss: 0.1156 - val_accuracy: 0.9506\n",
      "Epoch 41/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1265 - accuracy: 0.9511 - val_loss: 0.1151 - val_accuracy: 0.9502\n",
      "Epoch 42/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1257 - accuracy: 0.9515 - val_loss: 0.1138 - val_accuracy: 0.9535\n",
      "Epoch 43/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1256 - accuracy: 0.9518 - val_loss: 0.1139 - val_accuracy: 0.9527\n",
      "Epoch 44/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1252 - accuracy: 0.9520 - val_loss: 0.1134 - val_accuracy: 0.9537\n",
      "Epoch 45/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1241 - accuracy: 0.9521 - val_loss: 0.1124 - val_accuracy: 0.9541\n",
      "Epoch 46/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1241 - accuracy: 0.9526 - val_loss: 0.1118 - val_accuracy: 0.9533\n",
      "Epoch 47/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1235 - accuracy: 0.9527 - val_loss: 0.1122 - val_accuracy: 0.9534\n",
      "Epoch 48/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1230 - accuracy: 0.9529 - val_loss: 0.1115 - val_accuracy: 0.9545\n",
      "Epoch 49/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.1105 - val_accuracy: 0.9529\n",
      "Epoch 50/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1225 - accuracy: 0.9531 - val_loss: 0.1098 - val_accuracy: 0.9549\n",
      "Epoch 51/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1220 - accuracy: 0.9532 - val_loss: 0.1107 - val_accuracy: 0.9540\n",
      "Epoch 52/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1216 - accuracy: 0.9535 - val_loss: 0.1102 - val_accuracy: 0.9537\n",
      "Epoch 53/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1211 - accuracy: 0.9537 - val_loss: 0.1102 - val_accuracy: 0.9549\n",
      "Epoch 54/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1204 - accuracy: 0.9541 - val_loss: 0.1084 - val_accuracy: 0.9546\n",
      "Epoch 55/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1198 - accuracy: 0.9543 - val_loss: 0.1098 - val_accuracy: 0.9551\n",
      "Epoch 56/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1190 - accuracy: 0.9546 - val_loss: 0.1071 - val_accuracy: 0.9551\n",
      "Epoch 57/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1186 - accuracy: 0.9549 - val_loss: 0.1070 - val_accuracy: 0.9549\n",
      "Epoch 58/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1176 - accuracy: 0.9552 - val_loss: 0.1076 - val_accuracy: 0.9550\n",
      "Epoch 59/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1172 - accuracy: 0.9555 - val_loss: 0.1060 - val_accuracy: 0.9546\n",
      "Epoch 60/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1170 - accuracy: 0.9556 - val_loss: 0.1058 - val_accuracy: 0.9548\n",
      "Epoch 61/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1162 - accuracy: 0.9560 - val_loss: 0.1055 - val_accuracy: 0.9542\n",
      "Epoch 62/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.1051 - val_accuracy: 0.9542\n",
      "Epoch 63/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1155 - accuracy: 0.9564 - val_loss: 0.1040 - val_accuracy: 0.9555\n",
      "Epoch 64/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1146 - accuracy: 0.9568 - val_loss: 0.1049 - val_accuracy: 0.9647\n",
      "Epoch 65/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1141 - accuracy: 0.9571 - val_loss: 0.1049 - val_accuracy: 0.9675\n",
      "Epoch 66/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1136 - accuracy: 0.9573 - val_loss: 0.1021 - val_accuracy: 0.9555\n",
      "Epoch 67/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1134 - accuracy: 0.9577 - val_loss: 0.1024 - val_accuracy: 0.9565\n",
      "Epoch 68/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1130 - accuracy: 0.9579 - val_loss: 0.1016 - val_accuracy: 0.9557\n",
      "Epoch 69/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1126 - accuracy: 0.9581 - val_loss: 0.1009 - val_accuracy: 0.9556\n",
      "Epoch 70/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1124 - accuracy: 0.9584 - val_loss: 0.1020 - val_accuracy: 0.9562\n",
      "Epoch 71/80\n",
      "1455395/1455395 [==============================] - 4s 2us/sample - loss: 0.1124 - accuracy: 0.9585 - val_loss: 0.1020 - val_accuracy: 0.9658\n",
      "Epoch 72/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1116 - accuracy: 0.9588 - val_loss: 0.1005 - val_accuracy: 0.9554\n",
      "Epoch 73/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1113 - accuracy: 0.9590 - val_loss: 0.1005 - val_accuracy: 0.9568\n",
      "Epoch 74/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1108 - accuracy: 0.9591 - val_loss: 0.0995 - val_accuracy: 0.9573\n",
      "Epoch 75/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1104 - accuracy: 0.9594 - val_loss: 0.0996 - val_accuracy: 0.9570\n",
      "Epoch 76/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1102 - accuracy: 0.9596 - val_loss: 0.1001 - val_accuracy: 0.9668\n",
      "Epoch 77/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1101 - accuracy: 0.9597 - val_loss: 0.0983 - val_accuracy: 0.9684\n",
      "Epoch 78/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1096 - accuracy: 0.9597 - val_loss: 0.1006 - val_accuracy: 0.9542\n",
      "Epoch 79/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1092 - accuracy: 0.9601 - val_loss: 0.0974 - val_accuracy: 0.9664\n",
      "Epoch 80/80\n",
      "1455395/1455395 [==============================] - 3s 2us/sample - loss: 0.1087 - accuracy: 0.9604 - val_loss: 0.0982 - val_accuracy: 0.9683\n",
      "Binary labels accuracy =  0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.97      0.99      0.98    407101\n",
      "      Attack       0.95      0.85      0.90     78031\n",
      "\n",
      "    accuracy                           0.97    485132\n",
      "   macro avg       0.96      0.92      0.94    485132\n",
      "weighted avg       0.97      0.97      0.97    485132\n",
      "\n",
      "Sequential: f1=0.895 auc=0.956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PR Score 0.956383013973057\n"
     ]
    }
   ],
   "source": [
    "def Sequential(X, y_Label, y_Label_Category, y_attack):\n",
    "    \n",
    "    original_target_names=['Benign', 'DoS_Hulk', 'DDos', 'PortScan', 'DoS_GoldenEye', 'FTPPatator', 'DoS_slowlorus', 'DoS_Slowhttptest', 'SSHPatator', 'Bot', 'Web_Attack_Brute_Force', 'Web_Attack_XSS']\n",
    "    label_cat_names =['Benign', 'dos', 'ddos', 'probe','brute_force', 'web_based_attack', 'botnet']\n",
    "    label_attack_names = ['Benign', 'Attack']\n",
    "    \n",
    "    x1,x2,x3=X,X,X\n",
    "    loop_no=1\n",
    "    epoch = 80\n",
    "    batch = 1000\n",
    "    \n",
    "    \n",
    "    for i in range(0,3): \n",
    "\n",
    "        if i ==0:\n",
    "            y = y_Label\n",
    "            X =x1\n",
    "            out_layer = len(np.unique(y))\n",
    "            H_layer = 75\n",
    "        elif i==1:\n",
    "            y=y_Label_Category\n",
    "            X=x2\n",
    "            out_layer = len(np.unique(y))\n",
    "            H_layer = 73\n",
    "        elif i==2:\n",
    "            y=y_attack\n",
    "            X=x3\n",
    "            out_layer = len(np.unique(y))\n",
    "            H_layer = 40\n",
    "            \n",
    "\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(f'Sequential NN, training loop {loop_no} ... this loop contains {len(np.unique(y))} target labels...')\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "        X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)\n",
    "\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_hold, y_hold, test_size=0.5, random_state=0, stratify=y_hold)\n",
    "\n",
    "\n",
    "        # Normalise\n",
    "        min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "        # Apply normalisation to dataset\n",
    "        X_train = min_max_scaler.transform(X_train)\n",
    "        X_val = min_max_scaler.transform(X_val)\n",
    "        X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Flatten(input_shape=(input_layers,)), #input, value set by feature selection \n",
    "        tf.keras.layers.Dense(H_layer, activation='relu'), #Hidden layer\n",
    "        tf.keras.layers.Dropout(0.2), #dropou\n",
    "        tf.keras.layers.Dense(out_layer, activation='softmax') #Layer changes depending on amount of target variables\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        import os\n",
    "\n",
    "        log_dir = os.path.join(\n",
    "        \"train_logs\",\n",
    "        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        )\n",
    "\n",
    "        # TF callback that sets up TensorBoard with training logs.\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        # TF callback that stops training when best value of validationi loss function is reached. It also\n",
    "        # restores weights from the best training iteration.\n",
    "        eary_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "        history = model.fit(X_train,\n",
    "            y_train,\n",
    "            epochs=epoch,\n",
    "            batch_size = batch,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=1)\n",
    "            #callbacks=[tensorboard_callback, eary_stop_callback])\n",
    "\n",
    "        loop_no = loop_no + 1\n",
    "\n",
    "        y_pred = model.predict_classes(X_test, verbose=0)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        if i == 0:\n",
    "            print(f'Original labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=original_target_names))\n",
    "        elif i == 1:\n",
    "            print(f'Category labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_cat_names))\n",
    "        elif i == 2:\n",
    "            print(f'Binary labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_attack_names))\n",
    "\n",
    "            prob = model.predict_proba(X_test)\n",
    "            prob = prob[:, 1] #keep probabilites for only positive outcomes\n",
    "\n",
    "            model_precision, model_recall, _ = precision_recall_curve(y_test, prob)\n",
    "            pr_auc = average_precision_score(y_test, prob, average='weighted')\n",
    "\n",
    "            NN_f1, NN_auc = f1_score(y_test, y_pred), auc(model_recall, model_precision)\n",
    "\n",
    "            print('Sequential: f1=%.3f auc=%.3f' % (NN_f1, NN_auc))\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(model_recall, model_precision, label='auc={}'.format(pr_auc))\n",
    "            plt.title('Precision / Recall Curve')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.legend(loc='lower left')\n",
    "            plt.show()\n",
    "\n",
    "            print('Average PR Score {}'.format(pr_auc))\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "Sequential(X, y_Label, y_Label_Category, y_attack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7fa29a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Gaussian Naive Bayes classifier, training for loop 1 ... this loop contains 12 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of mislabeled points out of a total 485132 points : 383835\n",
      "\n",
      "Original labels accuracy =  0.21\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                Benign       1.00      0.07      0.14    407101\n",
      "              DoS_Hulk       0.00      0.44      0.00       388\n",
      "                  DDos       0.93      0.95      0.94     25601\n",
      "              PortScan       0.06      0.99      0.11      2056\n",
      "         DoS_GoldenEye       0.86      0.89      0.87     34302\n",
      "            FTPPatator       0.00      0.68      0.01      1035\n",
      "         DoS_slowlorus       0.05      0.60      0.08      1058\n",
      "      DoS_Slowhttptest       0.29      1.00      0.45      1096\n",
      "            SSHPatator       0.60      0.97      0.74     11461\n",
      "                   Bot       0.99      0.95      0.97       614\n",
      "Web_Attack_Brute_Force       0.00      0.10      0.00       289\n",
      "        Web_Attack_XSS       0.01      0.96      0.02       131\n",
      "\n",
      "              accuracy                           0.21    485132\n",
      "             macro avg       0.40      0.72      0.36    485132\n",
      "          weighted avg       0.96      0.21      0.25    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Gaussian Naive Bayes classifier, training for loop 1 ... this loop contains 7 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of mislabeled points out of a total 485132 points : 232879\n",
      "\n",
      "Category labels accuracy =  0.52\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Benign       1.00      0.44      0.61    407101\n",
      "             dos       0.00      0.42      0.00       388\n",
      "            ddos       0.09      0.99      0.17      1710\n",
      "           probe       0.87      0.96      0.91     25601\n",
      "     brute_force       0.28      0.94      0.43     38451\n",
      "web_based_attack       0.58      0.97      0.72     11461\n",
      "          botnet       0.01      0.94      0.02       420\n",
      "\n",
      "        accuracy                           0.52    485132\n",
      "       macro avg       0.40      0.81      0.41    485132\n",
      "    weighted avg       0.92      0.52      0.61    485132\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Gaussian Naive Bayes classifier, training for loop 1 ... this loop contains 2 target labels...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of mislabeled points out of a total 485132 points : 280841\n",
      "\n",
      "Binary labels accuracy =  0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.99      0.31      0.48    407101\n",
      "      Attack       0.22      0.99      0.35     78031\n",
      "\n",
      "    accuracy                           0.42    485132\n",
      "   macro avg       0.60      0.65      0.41    485132\n",
      "weighted avg       0.87      0.42      0.46    485132\n",
      "\n",
      "GaussianNB: f1=0.354 auc=0.617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PR Score 0.255916793742831\n"
     ]
    }
   ],
   "source": [
    "def GNB(X, y_Label, y_Label_Category, y_attack):\n",
    "    \n",
    "    loop_no=1\n",
    "    original_target_names=['Benign', 'DoS_Hulk', 'DDos', 'PortScan', 'DoS_GoldenEye', 'FTPPatator', 'DoS_slowlorus', 'DoS_Slowhttptest', 'SSHPatator', 'Bot', 'Web_Attack_Brute_Force', 'Web_Attack_XSS']\n",
    "    label_cat_names =['Benign', 'dos', 'ddos', 'probe','brute_force', 'web_based_attack', 'botnet']\n",
    "    label_attack_names = ['Benign', 'Attack']\n",
    "    \n",
    "    for i in range(0,3): \n",
    "\n",
    "        if i ==0:\n",
    "            y = y_Label\n",
    "            X =x1\n",
    "\n",
    "        elif i==1:\n",
    "            y=y_Label_Category\n",
    "            X=x2\n",
    "\n",
    "        elif i==2:\n",
    "            y=y_attack\n",
    "            X=x3\n",
    "\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(f'Gaussian Naive Bayes classifier, training for loop {loop_no} ... this loop contains {len(np.unique(y))} target labels...')\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "        X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)\n",
    "\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_hold, y_hold, test_size=0.5, random_state=0, stratify=y_hold)\n",
    "\n",
    "        min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "        # Apply normalisation to dataset\n",
    "        X_train = min_max_scaler.transform(X_train)\n",
    "        X_val = min_max_scaler.transform(X_val)\n",
    "        X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        gnb = GaussianNB()\n",
    "        y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "              % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "        print('')\n",
    "\n",
    "        if i == 0:\n",
    "            print(f'Original labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=original_target_names))\n",
    "        elif i == 1:\n",
    "            print(f'Category labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_cat_names))\n",
    "        elif i == 2:\n",
    "            print(f'Binary labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_attack_names))\n",
    "\n",
    "\n",
    "            gnb_prob = gnb.predict_proba(X_test)\n",
    "            gnb_prob = gnb_prob[:, 1] #keep probabilites for only positive outcomes\n",
    "\n",
    "            gnb_precision, gnb_recall, _ = precision_recall_curve(y_test, gnb_prob)\n",
    "            pr_auc = average_precision_score(y_test, gnb_prob, average='weighted')\n",
    "\n",
    "            gnb_f1, gnb_auc = f1_score(y_test, y_pred), auc(gnb_recall, gnb_precision)\n",
    "\n",
    "            print('GaussianNB: f1=%.3f auc=%.3f' % (gnb_f1, gnb_auc))\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(gnb_recall, gnb_precision, label='auc={}'.format(pr_auc))\n",
    "            plt.title('Precision / Recall Curve')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.legend(loc='lower left')\n",
    "            plt.show()\n",
    "\n",
    "            print('Average PR Score {}'.format(pr_auc))\n",
    "        \n",
    "GNB(X, y_Label, y_Label_Category, y_attack)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5429bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X, y_Label, y_Label_Category, y_attack):\n",
    "    \n",
    "    original_target_names=['Benign', 'DoS_Hulk', 'DDos', 'PortScan', 'DoS_GoldenEye', 'FTPPatator', 'DoS_slowlorus', 'DoS_Slowhttptest', 'SSHPatator', 'Bot', 'Web_Attack_Brute_Force', 'Web_Attack_XSS']\n",
    "    label_cat_names =['Benign', 'dos', 'ddos', 'probe','brute_force', 'web_based_attack', 'botnet']\n",
    "    label_attack_names = ['Benign', 'Attack']\n",
    "    from sklearn.svm import SVC\n",
    "    loop_no=1\n",
    "    \n",
    "    for i in range(0,3): \n",
    "\n",
    "        if i ==0:\n",
    "            y = y_Label\n",
    "            X =x1\n",
    "\n",
    "        elif i==1:\n",
    "            y=y_Label_Category\n",
    "            X=x2\n",
    "\n",
    "        elif i==2:\n",
    "            y=y_attack\n",
    "            X=x3\n",
    "\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(f'Support vector machine classifier, training for loop {loop_no} ... this loop contains {len(np.unique(y))} target labels...')\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "        X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)\n",
    "\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_hold, y_hold, test_size=0.5, random_state=0, stratify=y_hold)\n",
    "\n",
    "        min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "        # Apply normalisation to dataset\n",
    "        X_train = min_max_scaler.transform(X_train)\n",
    "        X_val = min_max_scaler.transform(X_val)\n",
    "        X_test = min_max_scaler.transform(X_test)\n",
    "        \n",
    "        c=0.1\n",
    "        gamma=1\n",
    "        \n",
    "        model = SVC(C=c, gamma=gamma, kernel='rbf')\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # print prediction results\n",
    "        predictions = model.predict(X_test)\n",
    "        print(classification_report(y_test, predictions))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if i == 0:\n",
    "            print(f'Original labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=original_target_names))\n",
    "        elif i == 1:\n",
    "            print(f'Category labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_cat_names))\n",
    "        elif i == 2:\n",
    "            print(f'Binary labels accuracy =  {\"{:.2f}\".format(accuracy)}')\n",
    "            print(classification_report(y_test, y_pred, target_names=label_attack_names))\n",
    "\n",
    "#SVM(X, y_Label, y_Label_Category, y_attack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
